from transformers import AutoModel, AutoTokenizer, BertTokenizer
from transformers import BertForSequenceClassification, Trainer, TrainingArguments, BertConfig, pipeline
import pandas as pd
import numpy as np
from tqdm import tqdm
import json
import pickle
from sklearn.metrics.pairwise import cosine_similarity

from utils import *

def main():
        #Data ë¶ˆëŸ¬ì˜¤ê¸°
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    
    # ë¹„ì†ì–´ ì‚¬ì „ 01
    slang_list_01 = []
    f = open("./List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/ko", 'r')
    lines = f.readlines()
    for line in lines:
        line = line.replace("\n", "")
        slang_list_01.append(line)
    f.close()

    # ë¹„ì†ì–´ ì‚¬ì „ 02
    slang_list_02 = []
    f = open("./korean-bad-words/korean-bad-words.md", 'r')
    lines = f.readlines()
    for line in lines:
        line = line.replace("\n", "")
        slang_list_02.append(line)
    f.close()

    # ë¹„ì†ì–´ ì‚¬ì „ 03
    with open('./Gentleman/resources/badwords.json') as json_file:
        json_data = json.load(json_file)
    slang_list_03 = json_data["badwords"]

    # ë¹„ì†ì–´ ì‚¬ì „ í†µí•©
    slang_list = slang_list_01 + slang_list_02 + slang_list_03
    slang_list = list(set(slang_list))
    
    dataset = pd.read_csv('ChatbotData.csv')
    
    dataset.drop_duplicates(subset=['Q'], inplace=True)
    #label ë³„ ë°ì´í„°
    dataset_zero=pd.DataFrame({"Question":dataset['Q'][:5261], "answer":dataset['A'][:5261]})
    dataset_one=pd.DataFrame({"Question":dataset['Q'][5261:8743], "answer":dataset['A'][5261:8743]})
    dataset_two=pd.DataFrame({"Question":dataset['Q'][8743:], "answer":dataset['A'][8743:]})
    
        #cls ìœ ì‚¬ë„ êµ¬í•˜ëŠ” ë¶€ë¶„
    MODEL_NAME = "bert-base-multilingual-cased"
    tokenizer_cls = AutoTokenizer.from_pretrained(MODEL_NAME)
    model_cls = AutoModel.from_pretrained(MODEL_NAME)

    #labelë³„ question datalist ìƒì„±
    chatbot_zero_Qlist = []
    for data in dataset_zero['Question']:
        chatbot_zero_Qlist.append(data)

    chatbot_one_Qlist = []
    for data in dataset_one['Question']:
        chatbot_one_Qlist.append(data)

    chatbot_two_Qlist = []
    for data in dataset_two['Question']:
        chatbot_two_Qlist.append(data)
        
    #labelë³„ answer datalist ìƒì„±   
    chatbot_zero_Alist = []
    for data in dataset_zero['answer']:
        chatbot_zero_Alist.append(data)

    chatbot_one_Alist = []
    for data in dataset_one['answer']:
        chatbot_one_Alist.append(data)

    chatbot_two_Alist = []
    for data in dataset_two['answer']:
        chatbot_two_Alist.append(data)

    #ê° data tokenizing
    data_cls_zero = []
    data_cls_one = []
    data_cls_two = []

    with open('./data_cls/data_cls_zero.pkl','rb') as f:
        data_cls_zero = pickle.load(f)

    with open('./data_cls/data_cls_one.pkl','rb') as f:
        data_cls_one = pickle.load(f)
        
    with open('./data_cls/data_cls_two.pkl','rb') as f:
        data_cls_two = pickle.load(f)
    
    config = BertConfig.from_pretrained(MODEL_NAME)
    config.num_labels = 3
    model = BertForSequenceClassification(config) 
    # model.load_state_dict(model_state)
    model.load_state_dict(torch.load('model_state_dict.pth'))
    model.to(device)
    model.eval()
    
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    
    #ì§ˆë¬¸ ì…ë ¥, tokeniz
       
    print("ì±—ë´‡ ê³°ì‹œë¦¬ğŸ» ì‹œì‘í•©ë‹ˆë‹¤")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit'ì´ë‚˜ 'ë'ì„ ì…ë ¥í•˜ì„¸ìš”")
    
    while(True) :
        query =input("ë‚˜ì˜ ì§ˆë¬¸ : ".rjust(30))
        if query == "quit" or query =="ë": break
        
        query_cls_hidden = get_cls_token(query, model_cls, tokenizer_cls)
    
        #ë‹µë³€ ìƒì„±, ì¶œë ¥
        if find_Badword(query, slang_list) :
            print('ìš•ì„¤ì´ í¬í•¨ëœ ì§ˆë¬¸ì…ë‹ˆë‹¤')

        elif sentences_predict(query, model, tokenizer, device) == 0:
            cos_sim = cosine_similarity(query_cls_hidden, data_cls_zero)

            top_question = np.argmax(cos_sim)
            print('ğŸ» : ', chatbot_zero_Alist[top_question])

        elif sentences_predict(query, model, tokenizer, device) == 1:
            cos_sim = cosine_similarity(query_cls_hidden, data_cls_one)

            top_question = np.argmax(cos_sim)

            print('ğŸ» : ', chatbot_one_Alist[top_question])

        elif sentences_predict(query, model, tokenizer, device) == 2:
            cos_sim = cosine_similarity(query_cls_hidden, data_cls_two)

            top_question = np.argmax(cos_sim)

            print('ğŸ» : ', chatbot_two_Alist[top_question])
            
if __name__ == "__main__":
    main()